{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "\n",
    "start=time()\n",
    "employee = sc.textFile(\"./employees.csv\")\n",
    "end = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_time(start ,end):\n",
    "    print (\"The time of the operation is :\" , (end-start) , \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of the operation is : 3.163187265396118 s\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "employee.collect()\n",
    "end = time()\n",
    "tell_time(start ,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Emp ID,Name Prefix,First Name,Middle Initial,Last Name,Gender,E Mail,Father's Name,Mother's Name,Mother's Maiden Name,Date of Birth,Time of Birth,Age in Yrs.,Weight in Kgs.,Date of Joining,Quarter of Joining,Half of Joining,Year of Joining,Month of Joining,Month Name of Joining,Short Month,Day of Joining,DOW of Joining,Short DOW,Age in Company (Years),Salary,Last % Hike,SSN,Phone No. ,Place Name,County,City,State,Zip,Region,User Name,Password\",\n",
       " '850297,Ms.,Shawna,W,Buck,F,shawna.buck@gmail.com,Rosario Buck,Keisha Buck,Hendricks,12/12/1971,6:34:47 AM,45.66,44,12/18/2010,Q4,H2,2010,12,December,Dec,18,Saturday,Sat,6.61,119090,17%,222-11-7603,702-771-7149,Las Vegas,Clark,Las Vegas,NV,89128,West,swbuck,ja8?k3BTF^]o@<&']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-47cb95363fd0>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-47cb95363fd0>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print without_header.first()\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "without_header = employee.filter(lambda r : (r!= header))\n",
    "print without_header.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airports = pd.read_csv('C:/Users/User/airports.csv')\n",
    "airport_freq = pd.read_csv('C:/Users/User/airport-frequencies.csv')\n",
    "runways = pd.read_csv('C:/Users/User/runways.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>scheduled_service</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>home_link</th>\n",
       "      <th>wikipedia_link</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6523</td>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>40.070801</td>\n",
       "      <td>-74.933601</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>no</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323361</td>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>38.704022</td>\n",
       "      <td>-101.473911</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>no</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6524</td>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>59.949200</td>\n",
       "      <td>-151.695999</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>no</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id ident           type                  name  latitude_deg  \\\n",
       "0    6523   00A       heliport     Total Rf Heliport     40.070801   \n",
       "1  323361  00AA  small_airport  Aero B Ranch Airport     38.704022   \n",
       "2    6524  00AK  small_airport          Lowell Field     59.949200   \n",
       "\n",
       "   longitude_deg  elevation_ft continent iso_country iso_region  municipality  \\\n",
       "0     -74.933601          11.0       NaN          US      US-PA      Bensalem   \n",
       "1    -101.473911        3435.0       NaN          US      US-KS         Leoti   \n",
       "2    -151.695999         450.0       NaN          US      US-AK  Anchor Point   \n",
       "\n",
       "  scheduled_service gps_code iata_code local_code home_link wikipedia_link  \\\n",
       "0                no      00A       NaN        00A       NaN            NaN   \n",
       "1                no     00AA       NaN       00AA       NaN            NaN   \n",
       "2                no     00AK       NaN       00AK       NaN            NaN   \n",
       "\n",
       "  keywords  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27656    3632\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports[airports.ident == 'KLAX'].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heliport', 'small_airport', 'closed', 'seaplane_base',\n",
       "       'balloonport', 'medium_airport', 'large_airport'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports[(airports.iso_region == 'US-CA') & (airports.type == 'seaplane_base')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>name</th>\n",
       "      <th>municipality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26027</th>\n",
       "      <td>KBAB</td>\n",
       "      <td>Beale Air Force Base</td>\n",
       "      <td>Marysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26866</th>\n",
       "      <td>KEDW</td>\n",
       "      <td>Edwards Air Force Base</td>\n",
       "      <td>Edwards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27656</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28183</th>\n",
       "      <td>KOAK</td>\n",
       "      <td>Metropolitan Oakland International Airport</td>\n",
       "      <td>Oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28239</th>\n",
       "      <td>KONT</td>\n",
       "      <td>Ontario International Airport</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29759</th>\n",
       "      <td>KSAN</td>\n",
       "      <td>San Diego International Airport</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29799</th>\n",
       "      <td>KSFO</td>\n",
       "      <td>San Francisco International Airport</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29820</th>\n",
       "      <td>KSJC</td>\n",
       "      <td>Norman Y. Mineta San Jose International Airport</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29842</th>\n",
       "      <td>KSMF</td>\n",
       "      <td>Sacramento International Airport</td>\n",
       "      <td>Sacramento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29848</th>\n",
       "      <td>KSNA</td>\n",
       "      <td>John Wayne Airport-Orange County Airport</td>\n",
       "      <td>Santa Ana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29897</th>\n",
       "      <td>KSUU</td>\n",
       "      <td>Travis Air Force Base</td>\n",
       "      <td>Fairfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30129</th>\n",
       "      <td>KVBG</td>\n",
       "      <td>Vandenberg Air Force Base</td>\n",
       "      <td>Lompoc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident                                             name   municipality\n",
       "26027  KBAB                             Beale Air Force Base     Marysville\n",
       "26866  KEDW                           Edwards Air Force Base        Edwards\n",
       "27656  KLAX                Los Angeles International Airport    Los Angeles\n",
       "28183  KOAK       Metropolitan Oakland International Airport        Oakland\n",
       "28239  KONT                    Ontario International Airport        Ontario\n",
       "29759  KSAN                  San Diego International Airport      San Diego\n",
       "29799  KSFO              San Francisco International Airport  San Francisco\n",
       "29820  KSJC  Norman Y. Mineta San Jose International Airport       San Jose\n",
       "29842  KSMF                 Sacramento International Airport     Sacramento\n",
       "29848  KSNA         John Wayne Airport-Orange County Airport      Santa Ana\n",
       "29897  KSUU                            Travis Air Force Base      Fairfield\n",
       "30129  KVBG                        Vandenberg Air Force Base         Lompoc"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports[(airports.iso_region == 'US-CA') & (airports.type == 'large_airport')][['ident','name','municipality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "        text = fake_file_handle.getvalue()\n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "    if text:\n",
    "        return text\n",
    "if __name__ == '__main__':\n",
    "    print(extract_text_from_pdf('pdf_textmining.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miner_text_generator.py\n",
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "def extract_text_by_page(pdf_path):\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            resource_manager = PDFResourceManager()\n",
    "            fake_file_handle = io.StringIO()\n",
    "            converter = TextConverter(resource_manager, fake_file_handle)\n",
    "            page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "            page_interpreter.process_page(page)\n",
    "            text = fake_file_handle.getvalue()\n",
    "            yield text\n",
    "            # close open handles\n",
    "            converter.close()\n",
    "            fake_file_handle.close()\n",
    "def extract_text(pdf_path):\n",
    "    for page in extract_text_by_page(pdf_path):\n",
    "        print(page)\n",
    "        print()\n",
    "if __name__ == '__main__':\n",
    "    print(extract_text('pdf_textmining.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle \n",
    "from operator import add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is not 0\n"
     ]
    }
   ],
   "source": [
    "if (i == 0):\n",
    "    print(\"i is 0\")\n",
    "else:\n",
    "    print(\"i is not 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from bqplot import pyplot as plt\n",
    "\n",
    "import bokeh\n",
    "\n",
    "import time\n",
    "import urllib\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "from math import pi\n",
    "from numpy import random\n",
    "from numpy.random import randn\n",
    "\n",
    "from io import StringIO\n",
    "from matplotlib.pyplot import *\n",
    "from scipy import stats\n",
    "from pandas_datareader import DataReader\n",
    "from datetime import datetime\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "\n",
    "%config SQL.conn_name = 'spark'\n",
    "%matplotlib inline\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "from pyspark import SparkContext , SparkConf\n",
    "from pyspark.sql import SQLContext , HiveContext\n",
    "\n",
    "from pyspark.sql import HiveContext\n",
    "SQLContext = HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_stream = ssc.textFileStream(\"sampleTextDir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = input_stream.flatMap(lambda l:l.split(\" \")).map(lambda w:(w,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = word_pairs.reduceByKey(lambda x,y : x + y)\n",
    "\n",
    "counts.pprint()\n",
    "ssc.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = list(zip(cycle([\"even\" , \"odd\"]) , range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 0), ('odd', 1), ('even', 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "increased = numbers.mapValues(lambda x:x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = increased.reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 100), ('odd', 110)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubled = rdd.map(lambda x : x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(4) PythonRDD[7] at RDD at PythonRDD.scala:48 []\\n |  ParallelCollectionRDD[6] at parallelize at PythonRDD.scala:489 []'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "TOTAL = 1000000\n",
    "dots = sc.parallelize([2.0 * np.random.random(2) - 1.0 for i in range(TOTAL)]).cache()\n",
    "print(\"Number of random points:\", dots.count())\n",
    "\n",
    "stats = dots.stats()\n",
    "print('Mean:', stats.mean())\n",
    "print('stdev:', stats.stdev())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14127096\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.map(lambda x : x * 10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_odd(x):\n",
    "    return (x % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.filter(is_odd).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([\"a\" , \"b\"]).cartesian(sc.parallelize(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize([1,1,4,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = rdd.map(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'a']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sc.parallelize([[1,1] , [1,2] , [2,3] , [3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 3)], [(1, 1), (1, 2), (3, 3)]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.repartitionAndSortWithinPartitions(2).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = ice_creams.cartesian(cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers1 = sc.parallelize(range(10000) , numSlices = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9618"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers1.countApproxDistinct(relativeSD = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(1000) , numSlices=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.saveAsTextFile(\"Our_test_numbers.gz\" , compressionCodecClass = \"org.apache.hadoop.io.compress.GzipCodec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.takeSample(withReplacement = True , num=10000 , seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sc.parallelize([(\"a\" , 1 ) , (\"b\" , 2) , (\"b\" , 3)] , numSlices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', <pyspark.resultiterable.ResultIterable at 0x12ef6525ac8>),\n",
       " ('a', <pyspark.resultiterable.ResultIterable at 0x12ef65258d0>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pairs.groupByKey().collect()[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_queue(x , queue=[]):\n",
    "    queue += [x]\n",
    "    return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.foreach(add_to_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_to_queue(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = sc.parallelize([(\"a\" , 1 ) ,(\"a\" , 2) (\"b\" , 3) , (\"c\" , 4)] , numSlices = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sc.parallelize([\"TX\", \"TX\",\"CA\",\"TX\",\"CA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TX', 3), ('CA', 2)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.map(lambda x : (x ,1)).reduceByKey(operator.add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_value = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_op(x,y):\n",
    "    x.add(y)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize([0,0,1,1,2,5,6,7,8,9]).map(lambda x : [\"even\" if (x % 2 == 0) else \"odd\" , x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', {0, 2, 6, 8}), ('odd', {1, 5, 7, 9})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.aggregateByKey(zero_value , seq_op , comb_op).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_op(x,y):\n",
    "    return x.union(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sc.parallelize([(\"B\" , 1) , (\"a\" , 1 ) , (\"A\" , 3) , (\"d\" , 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('A', 3), ('B', 1), ('d', 4)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sortByKey(keyfunc=lambda x : x.lower()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sc.parallelize([(1 , \"a\") , (2 , \"a\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sc.parallelize([(2 , \"b\") , (2 , \"c\") , (3 , \"d\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sc.parallelize([(2 , \"b\") , (3 , \"b\") , (2 , \"c\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [['a'], []]), (2, [['a'], ['b', 'c']]), (3, [[], ['d']])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cogroup(b).mapValues(lambda x : [list(x[0]) , list(x[1])]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.wholeTextFiles(\"sample_input\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.parallelize([\"a\" , 1 , {\"Key\" : \"value\"}]).saveAsPickleFile(\"picklefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 1, {'Key': 'value'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pickleFile(\"picklefile\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org.apache.hadoop.mapreduce\n",
    "sc.newAPIHadoopFile\n",
    "sc.newAPIHadoopRDD\n",
    "\n",
    "\n",
    "\n",
    "rdd.saveAsHadoopFile(\n",
    "path = \"output-file\",\n",
    "outputFormatClass = \"org.apache.hadoop.mapred.TextOutputFormat\",\n",
    "    keyClass=None,\n",
    "    valueClass= None,\n",
    "    keyConverter=None,\n",
    "    valueConverter=None,\n",
    "    conf=None,\n",
    "    compressionCodecClass= \"org.apache.hadoop.io.compress.GzipCodec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_data = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22, 23, 24, 25]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x : x + important_data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 43, 44, 45, 46]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x : x + important_data).repartition(2).map(lambda x : x + important_data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22, 23, 24, 25]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x:x + important_data.value).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    " evens = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_and_report(x):\n",
    "    global evens\n",
    "    if(x % 2 == 0):\n",
    "        evens += 1\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.map(inc_and_report).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evens.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sc.parallelize(range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 8, 12, 16, 1, 5, 9, 13, 17, 2, 6, 10, 14, 18, 3, 7, 11, 15, 19]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import AccumulatorParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetAccumulatorParam(AccumulatorParam):\n",
    "    def zero(self , initialValue):\n",
    "        s = Set()\n",
    "        s.add(initialValue)\n",
    "        return s \n",
    "    def addInPlace(self , v1 , v2):\n",
    "        return v1.union(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_seen = sc.accumulator(None , SetAccumulatorParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_and_note(x):\n",
    "    global ids_seen\n",
    "    ids_seen += x \n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.map(inc_and_note).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_stream = ssc.textFileStream(\"sample_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = input_stream.flatMap(lambda l:l.split(\" \")).map(lambda w : (w,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = word_pairs.reduceByKey(lambda x,y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.pprint() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:489"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5])\n",
    "\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(4) PythonRDD[3] at RDD at PythonRDD.scala:48 []\\n |  ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:489 []'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubled = rdd.map(lambda x : x * 2)\n",
    "\n",
    "doubled.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Div = sc.textFile(\"C:/Dividends.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = spark.read.csv( \"iris.csv\", header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sqlContext.read.load (\"iris.csv\", format='com.databricks.spark.csv',header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import HiveContext\n",
    "sqlContext = HiveContext(sc)\n",
    "#depts = sqlContext.sql(\"Select * from Departments\")\n",
    "sep_len = sqlContext.sql(\"select * from df1\")\n",
    "for rec in depts.collect():\n",
    "    print(rec)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DZONE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(firstName='Muriel', lastName=None, email='muriel@waterloo.edu', salary=140000)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
    "employee1 = Employee('Basher', 'armbrust', 'bash@edureka.co', 100000)\n",
    "employee2 = Employee('Daniel', 'meng', 'daniel@stanford.edu', 120000 )\n",
    "employee3 = Employee('Muriel', None, 'muriel@waterloo.edu', 140000 )\n",
    "employee4 = Employee('Rachel', 'wendell', 'rach_3@edureka.co', 160000 )\n",
    "employee5 = Employee('Zach', 'galifianakis', 'zach_g@edureka.co', 160000 )\n",
    "\n",
    "print(employee3)\n",
    "\n",
    "\n",
    "department1 = Row(id='123456', name='HR')\n",
    "department2 = Row(id='789012', name='OPS')\n",
    "department3 = Row(id='345678', name='FN')\n",
    "department4 = Row(id='901234', name='DEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24702.54270500423"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "expenditure = np.random.normal(25000,15000,10000)\n",
    "np.median(expenditure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299910051821.55994"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenditure = np.append(expenditure , [1000000000000000])\n",
    "np.mean(expenditure)\n",
    "#np.median(expenditure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 41, 43, 19, 34, 28, 30, 33, 34, 48, 32, 29, 21, 49, 45, 29, 30,\n",
       "       47, 29, 37, 35, 25, 49, 38, 31, 39, 18, 25, 26, 34, 46, 41, 49, 24,\n",
       "       20, 40, 16, 48, 24, 16, 27, 28, 29, 15, 41, 19, 46, 34, 18, 49, 24,\n",
       "       37, 42, 35, 23, 25, 42, 27, 29, 23, 16, 21, 20, 34, 22, 23, 18, 20,\n",
       "       38, 36, 39, 26, 43, 30, 22, 16, 20, 28, 16, 21, 44, 29, 39, 27, 42,\n",
       "       19, 35, 23, 19, 24, 15, 41, 36, 16, 17, 31, 25, 26, 41, 28, 40, 34,\n",
       "       37, 27, 45, 24, 35, 20, 37, 33, 46, 43, 20, 25, 41, 18, 29, 43, 34,\n",
       "       31, 37, 48, 16, 47, 29, 27, 38, 46, 17, 18, 46, 41, 34, 26, 40, 34,\n",
       "       46, 21, 39, 17, 33, 41, 48, 30, 43, 16, 45, 30, 30, 25, 31, 42, 29,\n",
       "       17, 21, 44, 37, 33, 28, 24, 38, 39, 38, 48, 21, 31, 46, 47, 41, 36,\n",
       "       19, 38, 24, 15, 18, 33, 45, 36, 33, 18, 32, 29, 34, 25, 36, 24, 17,\n",
       "       41, 19, 35, 37, 17, 33, 45, 20, 49, 33, 25, 47, 33])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenditure = np.random.randint(15 , high=50 , size=200)\n",
    "(expenditure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([29]), count=array([10]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.mode(expenditure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf , SparkContext\n",
    "lines = sc.textFile('C:/Users/User/Tempreture.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf , SparkContext\n",
    "autodata = sc.textFile('C:/Users/User/auto-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autodata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAKE,FUELTYPE,ASPIRE,DOORS,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE',\n",
       " 'subaru,gas,std,two,hatchback,fwd,four,69,4900,31,36,5118',\n",
       " 'chevrolet,gas,std,two,hatchback,fwd,three,48,5100,47,53,5151',\n",
       " 'mazda,gas,std,two,hatchback,fwd,four,68,5000,30,31,5195',\n",
       " 'toyota,gas,std,two,hatchback,fwd,four,62,4800,35,39,5348']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autodata.take(5)\n",
    "#autodata.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in autodata.collect():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colldata = sc.parallelize([3,5,4,7,4])\n",
    "colldata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_Line(line):\n",
    "    fields = line.split(',')\n",
    "    stationID = fields[0]\n",
    "    entryType = fields[2]\n",
    "    tempreture = float(fields[3]) * 0.1 * (9.0/5.0) + 32.0\n",
    "    return(stationID , entryType , tempreture )\n",
    "\n",
    "parsed_res = lines.map(parsed_Line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_station' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c3309587aa3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtmin_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m\"TMIN\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#tmin_filtered.take(10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtemp_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_station\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'temp_station' is not defined"
     ]
    }
   ],
   "source": [
    "tmin_filtered = parsed_res.filter(lambda x : \"TMIN\" in x[1])\n",
    "#tmin_filtered.take(10)\n",
    "temp_min = temp_station.reduceByKey(lambda x , y : min(x ,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
